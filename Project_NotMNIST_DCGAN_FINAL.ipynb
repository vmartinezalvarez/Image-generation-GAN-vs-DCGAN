{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_NotMNIST_DCGAN_FINAL",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vmartinezalvarez/Image-generation-GAN-vs-DCGAN/blob/master/Project_NotMNIST_DCGAN_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSZqixp2obkL",
        "colab_type": "text"
      },
      "source": [
        "### Import  libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNnmjYQsO0Lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv2DTranspose, Conv2D, UpSampling2D\n",
        "from keras.layers import BatchNormalization, Activation\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "# from keras.layers.convolutional import UpSampling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam, RMSprop \n",
        "from keras.preprocessing import image\n",
        "\n",
        "import os\n",
        "from skimage import io\n",
        "from skimage.transform import resize\n",
        "import tarfile\n",
        "import time\n",
        "from IPython import display\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MT4TOeniVLEy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "5e2241db-8099-4ccc-a893-0912adbaeffd"
      },
      "source": [
        "! pip install wget"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=8121917994edde1ffa29e110250eb4f1db9e38c23e9d73b113b2006951a4a219\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXKDucBGyoMj",
        "colab_type": "text"
      },
      "source": [
        "## notMNIST dataset\n",
        " The [notMNIST](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html) dataset is similar to MNIST, but looks a bit more like real data, that is, the data is much less clean compared to MNIST. \n",
        " \n",
        "There are 10 classes, with letters A-J taken from different fonts. \n",
        "\n",
        "The dataset consists of a small part cleaned by hand, approximately 1872 elements per class, and large uncleaned part, approximately 52909 elements per class. Two parts have approximately 0.5% and 6.5% label error rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0F7KDtKop4N",
        "colab_type": "text"
      },
      "source": [
        "#### Download notMNIST_large and notMNIST_small dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZoxD0ec_VLFO",
        "colab": {}
      },
      "source": [
        "import wget\n",
        "\n",
        "file_url_large = 'https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz'\n",
        "file_url_small = 'https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz'\n",
        "\n",
        "file_name_large = wget.download(file_url_large)\n",
        "file_name_small = wget.download(file_url_small)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_jE77kB_VLFc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3498be8c-5433-4948-9def-2aa2868a0f66"
      },
      "source": [
        "print(file_name_large)\n",
        "print(file_name_small)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "notMNIST_large.tar.gz\n",
            "notMNIST_small.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2axRSRrwVLFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc96219c-0b0d-4269-a73d-d4cf1bfd2481"
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "# extract notMNIST_large\n",
        "extract_large = tarfile.open(file_name_large)\n",
        "extract_large.extractall()\n",
        "\n",
        "# extract notMNIST_small\n",
        "extract_small = tarfile.open(file_name_small)\n",
        "extract_small.extractall()\n",
        "print ('Time to extract is {} sec'.format(time.time()-start))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to extract is 112.4398398399353 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5M3v39Do3ZR",
        "colab_type": "text"
      },
      "source": [
        "### Create the dataset to traing the DCGAN model\n",
        "\n",
        "The code below is intended to be used to generate a dataset with all the samples together, that is, a mix of the clean and unclean parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsAHSEZRVhmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training data\n",
        "train = []\n",
        "train_labels = []\n",
        "\n",
        "start = time.time()\n",
        "################### Letter A ######################### \n",
        "\n",
        "files = io.ImageCollection('notMNIST_large/A' + '/*.png') #  image path\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "files = io.ImageCollection('notMNIST_small/A' + '/*.png') \n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter B ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_large/B' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "    \n",
        "files =  io.ImageCollection('notMNIST_small/B' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter C ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_large/C' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/C' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter D ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_large/D' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]) \n",
        "    \n",
        "files =  io.ImageCollection('notMNIST_small/D' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
        "    \n",
        " ################### Letter E ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_large/E' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
        "    \n",
        "    \n",
        "files =  io.ImageCollection('notMNIST_small/E' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter F ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_large/F' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/F' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
        "    \n",
        "    \n",
        "################### Letter G #########################   \n",
        "files =  io.ImageCollection('notMNIST_large/G' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
        "    \n",
        "files =  io.ImageCollection('notMNIST_small/G' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
        "    \n",
        "################### Letter H  #########################   \n",
        "files =  io.ImageCollection('notMNIST_large/H' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/H' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
        "    \n",
        "    \n",
        "################### Letter I  #########################   \n",
        "files =  io.ImageCollection('notMNIST_large/I' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/I' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
        "    \n",
        "\n",
        "################### Letter J   #########################   \n",
        "files =  io.ImageCollection('notMNIST_large/J' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])\n",
        "    \n",
        "files =  io.ImageCollection('notMNIST_small/J' + '/*.png')\n",
        "for myFile in files:\n",
        "    train.append(resize(myFile,(28,28,1)))\n",
        "    train_labels.append([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])   \n",
        "    \n",
        "print ('Time to create dataset is {} sec'.format(time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEXjyQ0C55Ty",
        "colab_type": "text"
      },
      "source": [
        "### Create the dataset with only the clean part\n",
        "\n",
        "The code below is intended to be used to generate a dataset with all the samples in the clean part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddM8FRSZ554-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training data\n",
        "train_clean = []\n",
        "train_labels_clean = []\n",
        "\n",
        "start = time.time()\n",
        "################### Letter A ######################### \n",
        "\n",
        "files = io.ImageCollection('notMNIST_small/A' + '/*.png') \n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter B ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/B' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter C ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/C' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter D ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/D' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
        "    \n",
        " ################### Letter E ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/E' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])\n",
        "\n",
        "################### Letter F ######################### \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/F' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n",
        "    \n",
        "    \n",
        "################### Letter G #########################   \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/G' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n",
        "    \n",
        "################### Letter H  #########################   \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/H' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n",
        "    \n",
        "    \n",
        "################### Letter I  #########################   \n",
        "\n",
        "files =  io.ImageCollection('notMNIST_small/I' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])\n",
        "    \n",
        "\n",
        "################### Letter J   #########################   \n",
        "    \n",
        "files =  io.ImageCollection('notMNIST_small/J' + '/*.png')\n",
        "for myFile in files:\n",
        "    train_clean.append(resize(myFile,(28,28,1)))\n",
        "    train_labels_clean.append([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])   \n",
        "    \n",
        "print ('Time to create dataset is {} sec'.format(time.time()-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvQmLWlWphis",
        "colab_type": "text"
      },
      "source": [
        "#### Create the compressed dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oct9AwNQVqq2",
        "colab": {}
      },
      "source": [
        "# save numpy array as .npy formats\n",
        "np.save('train',train)\n",
        "np.save('train_labels',train_labels)\n",
        "np.savez_compressed('dataset', x_train=train, y_train=train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dbc90S106WTd"
      },
      "source": [
        "#### Create the compressed clean dataset  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lgcofGky6WTe",
        "colab": {}
      },
      "source": [
        "# save numpy array as .npy formats\n",
        "np.save('train_clean',train_clean)\n",
        "np.save('train_labels_clean',train_labels_clean)\n",
        "np.savez_compressed('dataset_clean', x_train_clean=train_clean, y_train_clean=train_labels_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LeT3qQZp6E1",
        "colab_type": "text"
      },
      "source": [
        "### Once created the dataset, download it to the hard disk and then upload it to google drive RIST, which is the destination folder for this project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbD4qiJRlQoQ",
        "colab_type": "text"
      },
      "source": [
        "#### Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82QAwKKim1Fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRgx9h7QnDxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls \"/content/drive/My Drive/Project\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V-Ukw3nZVqrG",
        "colab": {}
      },
      "source": [
        "def load_data(path):\n",
        "    with np.load(path) as f:\n",
        "        x_train, y_train = f['x_train_clean'], f['y_train_clean']\n",
        "        return (x_train, y_train)\n",
        "\n",
        "      \n",
        "my_path       = \"/content/drive/My Drive/Project/dataset.npz\"\n",
        "my_path_clean = \"/content/drive/My Drive/Project/dataset_clean.npz\"\n",
        "      \n",
        "(x_train_clean, y_train_clean) = load_data(my_path_clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08KhS8FtaSfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of samples\n",
        "x_train_clean.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_kzl1IDVqrQ",
        "colab": {}
      },
      "source": [
        "x_train_clean.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9pbZlZzXiSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# number of training samples for classes in the dataset\n",
        "y_train_clean.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAqTR3QTZtAG",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the dataset is well balanced across classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_lpHuc9zYM0",
        "colab_type": "text"
      },
      "source": [
        "#### Bellow we can see some examples of letter \"B\" "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4rHWxCUzT9f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "  \n",
        "idxs = np.random.randint(1872, 1872 + 500, 25)\n",
        "images = x_train_clean[idxs]\n",
        "  \n",
        "for i in range(images.shape[0]):\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.imshow(images[i, :, :, 0], cmap='gray')\n",
        "  plt.axis('off')     \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeBwBz6tr9di",
        "colab_type": "text"
      },
      "source": [
        "#### Show random samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egorjGQcr01R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "  \n",
        "idxs = np.random.randint(0, x_train_clean.shape[0], 25)\n",
        "images = x_train_clean[idxs]\n",
        "  \n",
        "for i in range(images.shape[0]):\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.imshow(images[i, :, :, 0], cmap='gray')\n",
        "  plt.axis('off')     \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9XAQFKxbc1j",
        "colab_type": "text"
      },
      "source": [
        "## Implement the DCGAN class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWer7UzSZOjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NotMNIST_DCGAN_1():\n",
        "  def __init__(self, height, width, channels, z_dim_noise):\n",
        "    \n",
        "    # input noise dimension\n",
        "    self.z_dim = z_dim_noise\n",
        "    # Input shape   \n",
        "    self.img_height   = height          \n",
        "    self.img_width    = width           \n",
        "    self.img_channels = channels        \n",
        "    self.img_shape    = (self.img_height, \n",
        "                         self.img_width,\n",
        "                         self.img_channels)\n",
        "    \n",
        "\n",
        "\n",
        "    # Create the discriminator\n",
        "    self.discriminator = self.discriminator_model()\n",
        "    self.discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0003, 0.7), metrics=['accuracy'])\n",
        "\n",
        "    # Create the generator\n",
        "    self.generator = self.generator_model()\n",
        "    \n",
        "    # Create the gan \n",
        "    self.gan = self.gan_model()\n",
        "    self.gan.compile(loss='binary_crossentropy', optimizer = Adam(0.0003, 0.7))  \n",
        "    \n",
        "    \n",
        "################################# gan model ###################################################\n",
        "  def gan_model(self):\n",
        "    \n",
        "    # input to gan\n",
        "    gan_input = Input(shape=(self.z_dim,))\n",
        "    \n",
        "    # generated fake images\n",
        "    generated_images = self.generator(gan_input)\n",
        "    \n",
        "    # freeze the discriminator\n",
        "    self.discriminator.trainable = False\n",
        "    \n",
        "    # Trains the generator to fool the discriminator\n",
        "    gan_output = self.discriminator(generated_images)\n",
        "    \n",
        "    return Model(gan_input, gan_output)\n",
        "\n",
        "################################# generator model ###################################################\n",
        "  def generator_model(self):\n",
        "    # input to generator\n",
        "    input_noise = Input(shape=(self.z_dim,))\n",
        "\n",
        "    # define sequential model \n",
        "    model = Sequential()    \n",
        "    # 1st  layer  \n",
        "    model.add(Dense(7*7*512, use_bias=False, activation=None, input_dim=self.z_dim ))\n",
        "    model.add(Reshape((7, 7, 512)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())  \n",
        "    # print(model.output_shape)\n",
        "    # 2nd  layer\n",
        "    model.add(Conv2DTranspose(256, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())  \n",
        "    # print(model.output_shape)\n",
        "    # 3rd layer      \n",
        "    model.add(Conv2DTranspose(128, kernel_size=(5,5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    # print(model.output_shape)\n",
        "    # 4th layer\n",
        "    model.add(Conv2DTranspose(64, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    # print(model.output_shape)\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(Conv2DTranspose(1, kernel_size=(5,5), strides=(2, 2), padding='same', \n",
        "                              use_bias=False, activation='tanh'))\n",
        "    \n",
        "    #print(model.output_shape)\n",
        "    #assert model.output_shape == (None, 28, 28, 1)\n",
        "    model.summary()\n",
        "    generator_output = model(input_noise)\n",
        "\n",
        "    return Model(input_noise, generator_output)\n",
        "\n",
        "#   def generator_model(self):\n",
        "#     # input to generator\n",
        "#     input_noise = Input(shape=(self.z_dim,))\n",
        "\n",
        "#     # define sequential model \n",
        "#     model = Sequential()\n",
        "#     # 1st  layer\n",
        "#     model.add(Dense(7*7*256, use_bias=False, activation=None, input_dim=self.z_dim ))\n",
        "#     model.add(Reshape((7, 7, 256)))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(LeakyReLU())\n",
        "#     # print(model.output_shape)      \n",
        "\n",
        "#     # 2nd layer      \n",
        "#     model.add(Conv2DTranspose(128, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(LeakyReLU()) \n",
        "#     # print(model.output_shape)\n",
        "#     # 3rd layer\n",
        "#     model.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(2, 2), padding='same', use_bias=False))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(LeakyReLU()) \n",
        "#     print(model.output_shape)\n",
        "#     # 4th layer\n",
        "#     model.add(Conv2DTranspose(32, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(LeakyReLU()) \n",
        "#     print(model.output_shape)\n",
        "    \n",
        "#     # Output layer\n",
        "#     model.add(Conv2DTranspose(1, kernel_size=(5,5), strides=(2, 2), padding='same', \n",
        "#                               use_bias=False, activation='tanh'))\n",
        "    \n",
        "# #     print(model.output_shape)\n",
        "# #     assert model.output_shape == (None, 28, 28, 1)\n",
        "#     model.summary()\n",
        "#     generator_output = model(input_noise)\n",
        "\n",
        "#     return Model(input_noise, generator_output)\n",
        "\n",
        "################################# discriminator model ###################################################\n",
        "\n",
        "  def discriminator_model(self):\n",
        "    \n",
        "    # input to discriminator\n",
        "    input_img = Input(shape=self.img_shape)\n",
        "    \n",
        "    # define sequential model\n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=self.img_shape))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.2))\n",
        "    # print(model.output_shape)\n",
        "    # 2nd  layer\n",
        "    model.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.25))\n",
        "    # 3rd  layer\n",
        "    model.add(Conv2D(256, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.25))\n",
        "    #print(model.output_shape)\n",
        "    #4th  layer\n",
        "    model.add(Conv2D(512, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "    #print(model.output_shape)\n",
        "    #Output layer   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    \n",
        "    discriminator_output = model(input_img)\n",
        "    \n",
        "    return Model(input_img, discriminator_output)\n",
        "  \n",
        "#################################### train method ################################################\n",
        "  \n",
        "  def train(self, epochs, train_data, batch_size=256, log_inter=50):\n",
        "    # shuffle dataset\n",
        "    train_data = self.randomize(train_data)\n",
        "    # Reshape it    \n",
        "    train_data = train_data.reshape(train_data.shape[0], 28, 28, 1).astype('float32')\n",
        "    train_data = (train_data - 0.5) / 0.5 # Normalize the images to [-1, 1]\n",
        "    # losses of Generator and Discriminator\n",
        "    losses = {\"Dis\":[], \"Gen\":[]} \n",
        "    \n",
        "    real = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "      #  Train Discriminator\n",
        "      # Select a batch of random  images\n",
        "      index = np.random.randint(0, train_data.shape[0], batch_size)\n",
        "      imgs = train_data[index]\n",
        "\n",
        "      # Sample noise and generate a batch of fake images\n",
        "      noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # important trick: add random noise to the labels\n",
        "      # Discriminator loss\n",
        "      d_loss_real = self.discriminator.train_on_batch(imgs, real+ 0.05*np.random.random(real.shape))\n",
        "      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake +0.05*np.random.random(fake.shape))\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "      losses[\"Dis\"].append(d_loss[0])\n",
        "      \n",
        "\n",
        "      #  train Generator via gan \n",
        "      g_loss = self.gan.train_on_batch(noise, real)\n",
        "      losses[\"Gen\"].append(g_loss)\n",
        "      \n",
        "      \n",
        "      # If at save interval => save generated image samples\n",
        "      if epoch % log_inter == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        self.generate_and_save_images(epoch)\n",
        "        self.plot_loss(losses)\n",
        "        #print('Epoch:{} [Discriminative loss: {:.4f}, accuracy: {:.2f}%],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], 100*d_loss[1], g_loss))  \n",
        "        print('Epoch:{} [Discriminative loss: {:.4f}],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], g_loss))  \n",
        "        \n",
        "\n",
        "        \n",
        "    display.clear_output(wait=True)\n",
        "    self.generate_and_save_images(epoch)\n",
        "    self.plot_loss(losses)\n",
        "      \n",
        "      \n",
        "  def generate_and_save_images(self, epoch):\n",
        "    # training is set to False, all layers run in inference mode\n",
        "    noise = np.random.normal(0, 1, (25, self.z_dim))\n",
        "    predictions =  self.generator.predict(noise)\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "      plt.subplot(5, 5, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "    label = 'Epoch {0}'.format(epoch)\n",
        "    fig.text(0.51, 0.05, label, ha='center',fontsize=14)      \n",
        "    #plt.savefig('NotMNIST_DCGAN_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "  def plot_loss(self, losses):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(losses[\"Dis\"], label='discrimininator loss')\n",
        "    plt.plot(losses[\"Gen\"], label='generator loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def randomize(self, dataset):\n",
        "    permutation = np.random.permutation(dataset.shape[0])\n",
        "    shuffled_dataset = dataset[permutation,:,:]\n",
        "    return shuffled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZOr41FXN1IG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imagen = image.array_to_img(x_train_clean[12], scale=False)\n",
        "plt.figure()\n",
        "plt.imshow(imagen,cmap='gray')    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XJMznRMmW3w7",
        "colab": {}
      },
      "source": [
        "height   = x_train_clean.shape[1]\n",
        "width    = x_train_clean.shape[2]\n",
        "channels = x_train_clean.shape[3]\n",
        "z_dim_noise = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knYw_maQIIBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Important, this dataset is between o and 1,\n",
        "print(np.min(x_train_clean), np.max(x_train_clean))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7edthGNIfAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_test = (x_train_clean - 0.5) / 0.5 # Normalize the images to [-1, 1]\n",
        "print(np.min(train_data_test), np.max(train_data_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-3aclA_vXhr",
        "colab_type": "text"
      },
      "source": [
        "#### Create the object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWP7t63T5OK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p NotMNIST_DCGAN_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YBzkUFBCW3w-",
        "colab": {}
      },
      "source": [
        "dcgan = NotMNIST_DCGAN(height, width, channels, z_dim_noise)\n",
        "dcgan.train(epochs=1000, train_data = x_train_clean, batch_size=256, log_inter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHYElNy8tkKM",
        "colab_type": "text"
      },
      "source": [
        "### Second Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cxbspek_Jftk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NotMNIST_DCGAN_2():\n",
        "  def __init__(self, height, width, channels, z_dim_noise):\n",
        "    # input noise dimension\n",
        "    self.z_dim = z_dim_noise\n",
        "    # Input shape   \n",
        "    self.img_height   = height          \n",
        "    self.img_width    = width           \n",
        "    self.img_channels = channels        \n",
        "    self.img_shape    = (self.img_height, \n",
        "                         self.img_width,\n",
        "                         self.img_channels)\n",
        "    \n",
        "\n",
        "    \n",
        "    # Create the discriminator\n",
        "    self.discriminator = self.discriminator_model()\n",
        "    self.discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0001, beta_1=0.99), metrics=['accuracy'])\n",
        "\n",
        "    # Create the generator\n",
        "    self.generator = self.generator_model()\n",
        "    \n",
        "    # Create the gan \n",
        "    self.gan = self.gan_model()\n",
        "    self.gan.compile(loss='binary_crossentropy', optimizer = Adam(lr=0.0001, beta_1=0.99))  \n",
        "    \n",
        "\n",
        "\n",
        "################################# generator model ###################################################\n",
        "  def generator_model(self):\n",
        "    # input to generator\n",
        "    input_noise = Input(shape=(self.z_dim,))\n",
        "\n",
        "    # define sequential model \n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Dense(7*7*256, use_bias=False, activation=None, input_dim=self.z_dim ))\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    # print(model.output_shape)      \n",
        "\n",
        "    # 2nd layer      \n",
        "    model.add(Conv2DTranspose(128, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    # print(model.output_shape)\n",
        "    # 3rd layer\n",
        "    model.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    print(model.output_shape)\n",
        "    # 4th layer\n",
        "    model.add(Conv2DTranspose(32, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    print(model.output_shape)\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(Conv2DTranspose(1, kernel_size=(5,5), strides=(2, 2), padding='same', \n",
        "                              use_bias=False, activation='tanh'))\n",
        "    \n",
        "#     print(model.output_shape)\n",
        "#     assert model.output_shape == (None, 28, 28, 1)\n",
        "    model.summary()\n",
        "    generator_output = model(input_noise)\n",
        "\n",
        "    return Model(input_noise, generator_output)\n",
        "\n",
        "################################# discriminator model ###################################################\n",
        "\n",
        "  def discriminator_model(self):\n",
        "    \n",
        "    # input to discriminator\n",
        "    input_img = Input(shape=self.img_shape)\n",
        "    \n",
        "    # define sequential model\n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=self.img_shape))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.2))\n",
        "    # print(model.output_shape)\n",
        "    # 2nd  layer\n",
        "    model.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.25))\n",
        "    # 3rd  layer\n",
        "    model.add(Conv2D(256, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "#     #print(model.output_shape)\n",
        "#     #4th  layer\n",
        "#     model.add(Conv2D(512, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "#     model.add(LeakyReLU())\n",
        "#     model.add(Dropout(0.3))\n",
        "#     #print(model.output_shape)\n",
        "#     #Output layer   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    \n",
        "    discriminator_output = model(input_img)\n",
        "    \n",
        "    return Model(input_img, discriminator_output)\n",
        "      \n",
        "################################# gan model ###################################################\n",
        "  def gan_model(self):\n",
        "    \n",
        "    # input to gan\n",
        "    gan_input = Input(shape=(self.z_dim,))\n",
        "    \n",
        "    # generated fake images\n",
        "    generated_images = self.generator(gan_input)\n",
        "    \n",
        "    # freeze the discriminator\n",
        "    self.discriminator.trainable = False\n",
        "    \n",
        "    # Trains the generator to fool the discriminator\n",
        "    gan_output = self.discriminator(generated_images)\n",
        "    \n",
        "    return Model(gan_input, gan_output)\n",
        "  \n",
        "#################################### train method ################################################\n",
        "  \n",
        "  def train(self, epochs, train_data, batch_size=256, log_inter=50):\n",
        "    # shuffle dataset\n",
        "    #train_data = self.randomize(train_data)\n",
        "    # Reshape it    \n",
        "    train_data = train_data.reshape(train_data.shape[0], 28, 28, 1).astype('float32')\n",
        "    train_data = (train_data - 0.5) / 0.5 # Normalize the images to [-1, 1]\n",
        "    # losses of Generator and Discriminator\n",
        "    losses = {\"Dis\":[], \"Gen\":[]} \n",
        "    \n",
        "    real = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    inicial = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      final = inicial + batch_size\n",
        "      imgs = train_data[inicial: final]\n",
        "      \n",
        "      #  Train Discriminator\n",
        "      # Select a batch of random  images\n",
        "#       index = np.random.randint(0, train_data.shape[0], batch_size)\n",
        "#       imgs = train_data[index]\n",
        "     \n",
        "      # Sample noise and generate a batch of fake images\n",
        "      noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # important trick: add random noise to the labels\n",
        "      # Discriminator loss\n",
        "      d_loss_real = self.discriminator.train_on_batch(imgs, fake + 0.07*np.random.random(fake.shape))\n",
        "      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, real -0.07*np.random.random(real.shape))\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "      losses[\"Dis\"].append(d_loss[0])\n",
        "      \n",
        "\n",
        "      #  train Generator via gan \n",
        "      g_loss = self.gan.train_on_batch(noise, fake)\n",
        "      losses[\"Gen\"].append(g_loss)\n",
        "      \n",
        "      \n",
        "      # If at save interval => save generated image samples\n",
        "      if epoch % log_inter == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        self.generate_and_save_images(epoch)\n",
        "        self.plot_loss(losses)\n",
        "        #print('Epoch:{} [Discriminative loss: {:.4f}, accuracy: {:.2f}%],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], 100*d_loss[1], g_loss))  \n",
        "        print('Epoch:{} [Discriminative loss: {:.4f}],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], g_loss))  \n",
        "      \n",
        "      inicial += batch_size\n",
        "      if (inicial > len(train_data) - batch_size):\n",
        "        inicial = 0  \n",
        "\n",
        "        \n",
        "    display.clear_output(wait=True)\n",
        "    self.generate_and_save_images(epoch)\n",
        "    self.plot_loss(losses)\n",
        "      \n",
        "      \n",
        "  def generate_and_save_images(self, epoch):\n",
        "    # training is set to False, all layers run in inference mode\n",
        "    noise = np.random.normal(0, 1, (25, self.z_dim))\n",
        "    predictions =  self.generator.predict(noise)\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "      plt.subplot(5, 5, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "    label = 'Epoch {0}'.format(epoch)\n",
        "    fig.text(0.51, 0.05, label, ha='center',fontsize=14)      \n",
        "    plt.savefig('NotMNIST_DCGAN_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "  def plot_loss(self, losses):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(losses[\"Dis\"], label='discrimininator loss')\n",
        "    plt.plot(losses[\"Gen\"], label='generator loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def randomize(self, dataset):\n",
        "    permutation = np.random.permutation(dataset.shape[0])\n",
        "    shuffled_dataset = dataset[permutation,:,:]\n",
        "    return shuffled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjGijuC-JfpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcgan_2 = NotMNIST_DCGAN_2(height, width, channels, z_dim_noise)\n",
        "dcgan_2.train(epochs=8000, train_data = x_train_clean, batch_size=256, log_inter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdNcorWQ6JOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "with imageio.get_writer('NotMNIST.gif', mode='I') as writer:\n",
        "  filenames = glob.glob('NotMNIST_DCGAN_images/image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.5)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "    \n",
        "# A hack to display the GIF inside this notebook\n",
        "os.rename('NotMNIST.gif', 'NotMNIST.gif.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vlmDc856LBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display.Image(filename=\"NotMNIST.gif.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26nYLv9dhg2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NotMNIST_DCGAN_3():\n",
        "  def __init__(self, height, width, channels, z_dim_noise):\n",
        "    # input noise dimension\n",
        "    self.z_dim = z_dim_noise\n",
        "    # Input shape   \n",
        "    self.img_height   = height          \n",
        "    self.img_width    = width           \n",
        "    self.img_channels = channels        \n",
        "    self.img_shape    = (self.img_height, \n",
        "                         self.img_width,\n",
        "                         self.img_channels)\n",
        "    \n",
        "\n",
        "    \n",
        "    # Create the discriminator\n",
        "    self.discriminator = self.discriminator_model()\n",
        "    self.discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005, beta_1=0.9), metrics=['accuracy'])\n",
        "\n",
        "    # Create the generator\n",
        "    self.generator = self.generator_model()\n",
        "    \n",
        "    # Create the gan \n",
        "    self.gan = self.gan_model()\n",
        "    self.gan.compile(loss='binary_crossentropy', optimizer = Adam(lr=0.0005, beta_1=0.91))  \n",
        "    \n",
        "\n",
        "\n",
        "################################# generator model ###################################################\n",
        "  def generator_model(self):\n",
        "    # input to generator\n",
        "    input_noise = Input(shape=(self.z_dim,))\n",
        "\n",
        "    # define sequential model \n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Dense(14*14*128, use_bias=False, activation=None, input_dim=self.z_dim ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Reshape((14, 14, 128)))\n",
        "    print(model.output_shape)      \n",
        "\n",
        "    # 2nd layer      \n",
        "    model.add(Conv2D(128, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    # print(model.output_shape)\n",
        "    model.add(Conv2DTranspose(128, kernel_size=(4, 4), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    # 3rd layer\n",
        "    model.add(Conv2DTranspose(128, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    print(model.output_shape)\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(Conv2D(1, kernel_size=(7,7), strides=(1, 1), padding='same', \n",
        "                              use_bias=False, activation='tanh'))\n",
        "    \n",
        "    print(model.output_shape)\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "    model.summary()\n",
        "    generator_output = model(input_noise)\n",
        "\n",
        "    return Model(input_noise, generator_output)\n",
        "\n",
        "################################# discriminator model ###################################################\n",
        "\n",
        "  def discriminator_model(self):\n",
        "    \n",
        "    # input to discriminator\n",
        "    input_img = Input(shape=self.img_shape)\n",
        "    \n",
        "    # define sequential model\n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=self.img_shape))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.2))\n",
        "    # print(model.output_shape)\n",
        "    # 2nd  layer\n",
        "    model.add(Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.2))\n",
        "    # 3rd  layer\n",
        "    model.add(Conv2D(128, kernel_size=(4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.2))\n",
        "    # 4th  layer\n",
        "    model.add(Conv2D(64, kernel_size=(4, 4), strides=(2, 2),  padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.3))\n",
        "    # print(model.output_shape)\n",
        "    # Output layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    \n",
        "    discriminator_output = model(input_img)\n",
        "    \n",
        "    return Model(input_img, discriminator_output)\n",
        "      \n",
        "################################# gan model ###################################################\n",
        "  def gan_model(self):\n",
        "    \n",
        "    # input to gan\n",
        "    gan_input = Input(shape=(self.z_dim,))\n",
        "    \n",
        "    # generated fake images\n",
        "    generated_images = self.generator(gan_input)\n",
        "    \n",
        "    # freeze the discriminator\n",
        "    self.discriminator.trainable = False\n",
        "    \n",
        "    # Trains the generator to fool the discriminator\n",
        "    gan_output = self.discriminator(generated_images)\n",
        "    \n",
        "    return Model(gan_input, gan_output)\n",
        "  \n",
        "#################################### train method ################################################\n",
        "  \n",
        "  def train(self, epochs, train_data, batch_size=256, log_inter=50):\n",
        "    # shuffle dataset\n",
        "    #train_data = self.randomize(train_data)\n",
        "    # Reshape it    \n",
        "    train_data = train_data.reshape(train_data.shape[0], 28, 28, 1).astype('float32')\n",
        "    train_data = (train_data - 0.5) / 0.5 # Normalize the images to [-1, 1]\n",
        "    # losses of Generator and Discriminator\n",
        "    losses = {\"Dis\":[], \"Gen\":[]} \n",
        "    \n",
        "    real = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    inicial = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      final = inicial + batch_size\n",
        "      imgs = train_data[inicial: final]\n",
        "      \n",
        "      #  Train Discriminator\n",
        "      # Select a batch of random  images\n",
        "#       index = np.random.randint(0, train_data.shape[0], batch_size)\n",
        "#       imgs = train_data[index]\n",
        "     \n",
        "      # Sample noise and generate a batch of fake images\n",
        "      noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # important trick: add random noise to the labels\n",
        "      # Discriminator loss\n",
        "      d_loss_real = self.discriminator.train_on_batch(imgs, fake + 0.07*np.random.random(fake.shape))\n",
        "      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, real -0.07*np.random.random(real.shape))\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "      losses[\"Dis\"].append(d_loss[0])\n",
        "      \n",
        "\n",
        "      #  train Generator via gan \n",
        "      g_loss = self.gan.train_on_batch(noise, fake)\n",
        "      losses[\"Gen\"].append(g_loss)\n",
        "      \n",
        "      \n",
        "      # If at save interval => save generated image samples\n",
        "      if epoch % log_inter == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        self.generate_and_save_images(epoch)\n",
        "        self.plot_loss(losses)\n",
        "        #print('Epoch:{} [Discriminative loss: {:.4f}, accuracy: {:.2f}%],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], 100*d_loss[1], g_loss))  \n",
        "        print('Epoch:{} [Discriminative loss: {:.4f}],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], g_loss))  \n",
        "      \n",
        "      inicial += batch_size\n",
        "      if (inicial > len(train_data) - batch_size):\n",
        "        inicial = 0  \n",
        "\n",
        "        \n",
        "    display.clear_output(wait=True)\n",
        "    self.generate_and_save_images(epoch)\n",
        "    self.plot_loss(losses)\n",
        "      \n",
        "      \n",
        "  def generate_and_save_images(self, epoch):\n",
        "    # training is set to False, all layers run in inference mode\n",
        "    noise = np.random.normal(0, 1, (25, self.z_dim))\n",
        "    predictions =  self.generator.predict(noise)\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "      plt.subplot(5, 5, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "    label = 'Epoch {0}'.format(epoch)\n",
        "    fig.text(0.51, 0.05, label, ha='center',fontsize=14)      \n",
        "    plt.savefig('NotMNIST_DCGAN_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "  def plot_loss(self, losses):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(losses[\"Dis\"], label='discrimininator loss')\n",
        "    plt.plot(losses[\"Gen\"], label='generator loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def randomize(self, dataset):\n",
        "    permutation = np.random.permutation(dataset.shape[0])\n",
        "    shuffled_dataset = dataset[permutation,:,:]\n",
        "    return shuffled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LUlhle6hgzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcgan_3 = NotMNIST_DCGAN_3(height, width, channels, z_dim_noise)\n",
        "dcgan_3.train(epochs=8000, train_data = x_train_clean, batch_size=256, log_inter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDbnUsGDhgwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD2TB9XThgsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzoYj_wWLfav",
        "colab_type": "text"
      },
      "source": [
        "## Model NotMNIST_DCGAN_4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nb6ZMvqLLph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NotMNIST_DCGAN_4():\n",
        "  def __init__(self, height, width, channels, z_dim_noise):\n",
        "    # input noise dimension\n",
        "    self.z_dim = z_dim_noise\n",
        "    # Input shape   \n",
        "    self.img_height   = height          \n",
        "    self.img_width    = width           \n",
        "    self.img_channels = channels        \n",
        "    self.img_shape    = (self.img_height, \n",
        "                         self.img_width,\n",
        "                         self.img_channels)\n",
        "    \n",
        "\n",
        "    \n",
        "    # Create the discriminator\n",
        "    self.discriminator = self.discriminator_model()\n",
        "    self.discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0004, beta_1=0.9,decay=1e-8), metrics=['accuracy'])\n",
        "\n",
        "    # Create the generator\n",
        "    self.generator = self.generator_model()\n",
        "    \n",
        "    # Create the gan \n",
        "    self.gan = self.gan_model()\n",
        "    self.gan.compile(loss='binary_crossentropy', optimizer = Adam(lr=0.0002, beta_1=0.9,decay=1e-8))  \n",
        "    \n",
        "\n",
        "\n",
        "################################# generator model ###################################################\n",
        "  def generator_model(self):\n",
        "    # input to generator\n",
        "    input_noise = Input(shape=(self.z_dim,))\n",
        "\n",
        "    # define sequential model \n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Dense(7*7*256, use_bias=False, activation=None, input_dim=self.z_dim ))\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU())\n",
        "    # print(model.output_shape)      \n",
        "\n",
        "    # 2nd layer      \n",
        "    model.add(Conv2DTranspose(128, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    # print(model.output_shape)\n",
        "    # 3rd layer\n",
        "    model.add(Conv2DTranspose(64, kernel_size=(3,3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    print(model.output_shape)\n",
        "    # 4th layer\n",
        "    model.add(Conv2DTranspose(32, kernel_size=(5,5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU()) \n",
        "    print(model.output_shape)\n",
        "    \n",
        "    # Output layer\n",
        "    model.add(Conv2DTranspose(1, kernel_size=(5,5), strides=(2, 2), padding='same', \n",
        "                              use_bias=False, activation='tanh'))\n",
        "    \n",
        "#     print(model.output_shape)\n",
        "#     assert model.output_shape == (None, 28, 28, 1)\n",
        "    model.summary()\n",
        "    generator_output = model(input_noise)\n",
        "\n",
        "    return Model(input_noise, generator_output)\n",
        "\n",
        "################################# discriminator model ###################################################\n",
        "\n",
        "  def discriminator_model(self):\n",
        "    \n",
        "    # input to discriminator\n",
        "    input_img = Input(shape=self.img_shape)\n",
        "    \n",
        "    # define sequential model\n",
        "    model = Sequential()\n",
        "    # 1st  layer\n",
        "    model.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=self.img_shape))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.2))\n",
        "    # print(model.output_shape)\n",
        "    # 2nd  layer\n",
        "    model.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.25))\n",
        "    # 3rd  layer\n",
        "    model.add(Conv2D(256, kernel_size=(5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(LeakyReLU())\n",
        "    model.add(Dropout(0.35))\n",
        "#     #print(model.output_shape)\n",
        "#     #Output layer   \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    \n",
        "    discriminator_output = model(input_img)\n",
        "    \n",
        "    return Model(input_img, discriminator_output)\n",
        "      \n",
        "################################# gan model ###################################################\n",
        "  def gan_model(self):\n",
        "    \n",
        "    # input to gan\n",
        "    gan_input = Input(shape=(self.z_dim,))\n",
        "    \n",
        "    # generated fake images\n",
        "    generated_images = self.generator(gan_input)\n",
        "    \n",
        "    # freeze the discriminator\n",
        "    self.discriminator.trainable = False\n",
        "    \n",
        "    # Trains the generator to fool the discriminator\n",
        "    gan_output = self.discriminator(generated_images)\n",
        "    \n",
        "    return Model(gan_input, gan_output)\n",
        "  \n",
        "#################################### train method ################################################\n",
        "  \n",
        "  def train(self, epochs, train_data, batch_size=256, log_inter=50):\n",
        "    # shuffle dataset\n",
        "    #train_data = self.randomize(train_data)\n",
        "    # Reshape it    \n",
        "    train_data = train_data.reshape(train_data.shape[0], 28, 28, 1).astype('float32')\n",
        "    train_data = (train_data - 0.5) / 0.5 # Normalize the images to [-1, 1]\n",
        "    # losses of Generator and Discriminator\n",
        "    losses = {\"Dis\":[], \"Gen\":[]} \n",
        "    \n",
        "    real = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    inicial = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      \n",
        "      final = inicial + batch_size\n",
        "      imgs = train_data[inicial: final]\n",
        "      \n",
        "      #  Train Discriminator\n",
        "      # Select a batch of random  images\n",
        "#       index = np.random.randint(0, train_data.shape[0], batch_size)\n",
        "#       imgs = train_data[index]\n",
        "     \n",
        "      # Sample noise and generate a batch of fake images\n",
        "      noise = np.random.normal(0, 1, (batch_size, self.z_dim))\n",
        "      gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "      # important trick: add random noise to the labels\n",
        "      # Discriminator loss\n",
        "      d_loss_real = self.discriminator.train_on_batch(imgs, fake + 0.05*np.random.random(fake.shape))\n",
        "      d_loss_fake = self.discriminator.train_on_batch(gen_imgs, real -0.05*np.random.random(real.shape))\n",
        "      d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "      losses[\"Dis\"].append(d_loss[0])\n",
        "      \n",
        "\n",
        "      #  train Generator via gan \n",
        "      g_loss = self.gan.train_on_batch(noise, fake)\n",
        "      losses[\"Gen\"].append(g_loss)\n",
        "      \n",
        "      \n",
        "      # If at save interval => save generated image samples\n",
        "      if epoch % log_inter == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        self.generate_and_save_images(epoch)\n",
        "        self.plot_loss(losses)\n",
        "        print('Epoch:{} [Discriminative loss: {:.4f}],[Generative loss: {:.4f}]'.format(epoch, d_loss[0], g_loss))  \n",
        "      \n",
        "      inicial += batch_size\n",
        "      if (inicial > len(train_data) - batch_size):\n",
        "        inicial = 0  \n",
        "\n",
        "        \n",
        "    display.clear_output(wait=True)\n",
        "    self.generate_and_save_images(epoch)\n",
        "    self.plot_loss(losses)\n",
        "      \n",
        "      \n",
        "  def generate_and_save_images(self, epoch):\n",
        "    # training is set to False, all layers run in inference mode\n",
        "    noise = np.random.normal(0, 1, (25, self.z_dim))\n",
        "    predictions =  self.generator.predict(noise)\n",
        "\n",
        "    fig = plt.figure(figsize=(5,5))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "      plt.subplot(5, 5, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "    label = 'Epoch {0}'.format(epoch)\n",
        "    fig.text(0.51, 0.05, label, ha='center',fontsize=14)      \n",
        "    plt.savefig('NotMNIST_DCGAN_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "  def plot_loss(self, losses):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.plot(losses[\"Dis\"], label='discrimininator loss')\n",
        "    plt.plot(losses[\"Gen\"], label='generator loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "  def randomize(self, dataset):\n",
        "    permutation = np.random.permutation(dataset.shape[0])\n",
        "    shuffled_dataset = dataset[permutation,:,:]\n",
        "    return shuffled_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhn_Tf-zLRl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dcgan_4 = NotMNIST_DCGAN_4(height, width, channels, z_dim_noise)\n",
        "dcgan_4.train(epochs=50000, train_data = x_train_clean, batch_size=512, log_inter=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FY6qTrjuLZ0g",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "with imageio.get_writer('NotMNIST.gif', mode='I') as writer:\n",
        "  filenames = glob.glob('NotMNIST_DCGAN_images/image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  last = -1\n",
        "  for i,filename in enumerate(filenames):\n",
        "    frame = 2*(i**0.9)\n",
        "    if round(frame) > round(last):\n",
        "      last = frame\n",
        "    else:\n",
        "      continue\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "    \n",
        "# A hack to display the GIF inside this notebook\n",
        "os.rename('NotMNIST.gif', 'NotMNIST.gif.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8qRtTrAyLZ0o",
        "colab": {}
      },
      "source": [
        "display.Image(filename=\"NotMNIST.gif.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1No1aYTLRXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r /content/file.zip /content/NotMNIST_DCGAN_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-YpfOLFpw3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}